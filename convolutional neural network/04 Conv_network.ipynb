{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "img_rows , img_cols , img_ch = 28 , 28 ,1 \n",
    "input_shape = (img_rows , img_cols , img_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train , y_train ) ,(x_test , y_test )  = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/ 255.0\n",
    "x_test  = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import (Input, Activation, Dense, Flatten, Conv2D, \n",
    "                                     MaxPooling2D, Dropout, BatchNormalization)\n",
    "\n",
    "epochs      = 200\n",
    "batch_size  = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def con_layer(x , kernal , bias , s ):\n",
    "    z = tf.nn.conv2d( x , kernal , strides=[1 , s , s, 1] , padding='VALID')\n",
    "    z = tf.nn.relu(z + bias )\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv_layer(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, num_kernals = 32 , kernal_size = (3 , 3 ) , stride= 1):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.num_kernals = num_kernals\n",
    "        self.kernal_size = kernal_size\n",
    "        self.stride = stride\n",
    "        \n",
    "    def build( self, inputs ):\n",
    "        num_channels = inputs[-1]\n",
    "        kernals_shape = (num_channels , *self.kernal_size , self.num_kernals)\n",
    "        \n",
    "        glorot_init = tf.initializers.GlorotUniform()\n",
    "        self.kernels = self.add_weight(name= 'kernal',\n",
    "                                      shape = kernals_shape ,\n",
    "                                      initializer = glorot_init ,\n",
    "                                      trainable = True)\n",
    "        self.bias = self.add_weight(name = 'bias',\n",
    "                                   shape = (self.num_kernals,),\n",
    "                                   initializer = 'random_normal',\n",
    "                                   trainable = True)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return con_layer(inputs , self.kernels , self.bias , self.stride)\n",
    "    \n",
    "    def get_config(self):\n",
    "        {\n",
    "          'kernel_size': self.kernel_size,\n",
    "            'strides': self.strides,\n",
    "            'use_bias': self.use_bias\n",
    "        }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "def l2_reg(coef=1e-2):\n",
    "    \"\"\"\n",
    "    Returns a function computing a weighed L2 norm of a given tensor.\n",
    "    (this is basically a reimplementation of f.keras.regularizers.l2())\n",
    "    :param coef:    Weight for the norm\n",
    "    :return:        Loss function\n",
    "    \"\"\"\n",
    "    return lambda x: tf.reduce_sum(x ** 2) * coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvWithRegularizers(SimpleConv_layer):\n",
    "    \n",
    "    def __init__(self, num_kernels = 32 , \n",
    "                kernel_size = (3 ,3 ) ,\n",
    "                stride =  1, \n",
    "                kernel_regularizer = l2_reg(),\n",
    "                bias_regularizer = None ):\n",
    "        super().__init__(num_kernels , kernel_size , stride)\n",
    "        self.kernel_regularizer = kernel_regularizer\n",
    "        self.bias_regularizer = bias_regularizer\n",
    "        \n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        super().build(input_shape)\n",
    "        if self.kernel_regularizer is not None:\n",
    "            self.add_loss(partial(self.kernel_regularizer, self.kernels))\n",
    "        if self.bias_regularizer is not None:\n",
    "            self.add_loss(partial(self.bias_regularizer, self.bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = ConvWithRegularizers(num_kernels=32, kernel_size=(3, 3), stride=1,\n",
    "                            kernel_regularizer=l2_reg(1.), bias_regularizer=l2_reg(1.))\n",
    "conv.build(input_shape=tf.TensorShape((None, 28, 28, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: id=46, shape=(), dtype=float32, numpy=5.410931>, <tf.Tensor: id=53, shape=(), dtype=float32, numpy=0.08222303>]\n"
     ]
    }
   ],
   "source": [
    "print(conv.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
