{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_YOLO_BACKEND_PATH  = \"full_yolo_backend.h5\"   # should be hosted on a server\n",
    "TINY_YOLO_BACKEND_PATH  = \"tiny_yolo_backend.h5\"   # should be hosted on a server\n",
    "SQUEEZENET_BACKEND_PATH = \"squeezenet_backend.h5\"  # should be hosted on a server\n",
    "MOBILENET_BACKEND_PATH  = \"mobilenet_backend.h5\"   # should be hosted on a server\n",
    "INCEPTION3_BACKEND_PATH = \"inception_backend.h5\"   # should be hosted on a server\n",
    "VGG16_BACKEND_PATH      = \"vgg16_backend.h5\"       # should be hosted on a server\n",
    "RESNET50_BACKEND_PATH   = \"resnet50_backend.h5\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseFeatureExtractor(object):\n",
    "    \n",
    "    def __init__( self, input_size ) :\n",
    "        raise NotImplementedError(\"Error Message\")\n",
    "        \n",
    "    def normalize( self, image ):\n",
    "        raise NotImplementedError(\"Error Message \")\n",
    "        \n",
    "    def get_output_shape(self):\n",
    "        return self.feature_extractor.get_output_shape_at(-1)[1:3]\n",
    "\n",
    "    def extract(self, input_image):\n",
    "        return self.feature_extractor(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullYoloFeature(BaseFeatureExtractor):\n",
    "    \n",
    "    def __init__( self, input_size ):\n",
    "        \n",
    "        input_image = Input(shape = (input_size , input_size , 3))\n",
    "        \n",
    "        def space_to_depth_x2(x):\n",
    "            return tf.nn.space_to_depth(x , block_size = 2 )\n",
    "        \n",
    "        \n",
    "        def Conv_block( inputs  , filters , kernel_size = 3 , strides = 1 , name = 1 , use_bias = False , use_pooling= False   ):\n",
    "\n",
    "            x = Conv2D(filters , kernel_size=(kernel_size , kernel_size) , strides=(strides , strides) ,\n",
    "                      padding = 'same' , name = \"conv_\" + str(name) , use_bias=use_bias)(inputs)\n",
    "            x = BatchNormalization(name = 'norm_' + str(name))(x)\n",
    "            x = LeakyReLU(alpha=0.1)(x)\n",
    "            if use_pooling:\n",
    "                x = MaxPooling2D(pool_size=( 2 , 2 ))(x)\n",
    "            return x \n",
    "        \n",
    "        \n",
    "        x = Conv_block(input_image ,32 , name = 1 , use_pooling = True)\n",
    "        \n",
    "        x = Conv_block( x , 64 , name =  2 , use_pooling = True )\n",
    "        x = Conv_block( x , 128 , name =  3 , use_pooling=False)\n",
    "        x = Conv_block( x , 64 ,  name =  4 , use_pooling=False )\n",
    "        \n",
    "        x = Conv_block( x , 128 , name =  5 , use_pooling=True)\n",
    "        x = Conv_block( x , 256 , name =  6 , use_pooling=False)\n",
    "        x = Conv_block( x , 128 ,  name =  7 , use_pooling=False )\n",
    "        \n",
    "        \n",
    "        x = Conv_block( x , 256 , name =  8 , use_pooling=True)\n",
    "        x = Conv_block( x , 512 , name =  9 , use_pooling=False)\n",
    "        x = Conv_block( x , 256 ,  name = 10 , use_pooling=False )\n",
    "        \n",
    "        \n",
    "        x = Conv_block( x , 512 , name =  11 , use_pooling=False)\n",
    "        x = Conv_block( x , 256 ,  name = 12 , use_pooling=False )\n",
    "        \n",
    "        \n",
    "        x = Conv_block( x , 512 , name =  13 , use_pooling=False)\n",
    "        \n",
    "        skip_connection  =  x\n",
    "        x = MaxPooling2D(pool_size=( 2 , 2 ))(x)\n",
    "        \n",
    "        \n",
    "        x = Conv_block( x , 1024 , kernel_size= 3 ,name =  14 , use_pooling=False)\n",
    "        x = Conv_block( x , 512 , kernel_size= 1 ,name =  15 , use_pooling=False)\n",
    "        x = Conv_block( x , 1024 , kernel_size= 3 ,name =  16 , use_pooling=False)\n",
    "        x = Conv_block( x , 512 , kernel_size= 1 ,name =  17 , use_pooling=False)\n",
    "        \n",
    "        x = Conv_block( x , 1024 , kernel_size= 3 ,name =  18 , use_pooling=False)\n",
    "        x = Conv_block( x , 1024 , kernel_size= 3 ,name =  19 , use_pooling=False)\n",
    "        x = Conv_block( x , 1024 , kernel_size= 3 ,name =  20 , use_pooling=False)\n",
    "       \n",
    "    \n",
    "        skip_connection = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_21', use_bias=False)(skip_connection)\n",
    "        skip_connection = BatchNormalization(name='norm_21')(skip_connection)\n",
    "        skip_connection = LeakyReLU(alpha=0.1)(skip_connection)\n",
    "        skip_connection = Lambda(space_to_depth_x2)(skip_connection)\n",
    "        \n",
    "        x = concatenate([skip_connection, x])\n",
    "        \n",
    "        x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_22', use_bias=False)(x)\n",
    "        x = BatchNormalization(name='norm_22')(x)\n",
    "        x = LeakyReLU(alpha=0.1)(x)\n",
    "        \n",
    "        \n",
    "        self.feature_extractor = Model(input_image, x) \n",
    "        #self.feature_extractor.load_weights(FULL_YOLO_BACKEND_PATH)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def normalize( self, image ):\n",
    "        return image /255.\n",
    "        \n",
    "        \n",
    "                    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_value = Input([512 , 512 , 3 ])\n",
    "model = FullYoloFeature(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 512, 512, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 512, 512, 32) 864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_1 (BatchNormalization)     (None, 512, 512, 32) 128         conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 512, 512, 32) 0           norm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 256, 256, 32) 0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 256, 256, 64) 18432       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_2 (BatchNormalization)     (None, 256, 256, 64) 256         conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 256, 256, 64) 0           norm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 128, 128, 64) 0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 128, 128, 128 73728       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_3 (BatchNormalization)     (None, 128, 128, 128 512         conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 128, 128, 128 0           norm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Conv2D)                 (None, 128, 128, 64) 73728       leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "norm_4 (BatchNormalization)     (None, 128, 128, 64) 256         conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 128, 128, 64) 0           norm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_5 (Conv2D)                 (None, 128, 128, 128 73728       leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "norm_5 (BatchNormalization)     (None, 128, 128, 128 512         conv_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 128, 128, 128 0           norm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 64, 64, 128)  0           leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_6 (Conv2D)                 (None, 64, 64, 256)  294912      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_6 (BatchNormalization)     (None, 64, 64, 256)  1024        conv_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 64, 64, 256)  0           norm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_7 (Conv2D)                 (None, 64, 64, 128)  294912      leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "norm_7 (BatchNormalization)     (None, 64, 64, 128)  512         conv_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 64, 64, 128)  0           norm_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_8 (Conv2D)                 (None, 64, 64, 256)  294912      leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "norm_8 (BatchNormalization)     (None, 64, 64, 256)  1024        conv_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 64, 64, 256)  0           norm_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 32, 32, 256)  0           leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_9 (Conv2D)                 (None, 32, 32, 512)  1179648     max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_9 (BatchNormalization)     (None, 32, 32, 512)  2048        conv_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 32, 32, 512)  0           norm_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_10 (Conv2D)                (None, 32, 32, 256)  1179648     leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "norm_10 (BatchNormalization)    (None, 32, 32, 256)  1024        conv_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 32, 32, 256)  0           norm_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_11 (Conv2D)                (None, 32, 32, 512)  1179648     leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_11 (BatchNormalization)    (None, 32, 32, 512)  2048        conv_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 32, 32, 512)  0           norm_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_12 (Conv2D)                (None, 32, 32, 256)  1179648     leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_12 (BatchNormalization)    (None, 32, 32, 256)  1024        conv_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 32, 32, 256)  0           norm_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_13 (Conv2D)                (None, 32, 32, 512)  1179648     leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_13 (BatchNormalization)    (None, 32, 32, 512)  2048        conv_13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 32, 32, 512)  0           norm_13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 16, 16, 512)  0           leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_14 (Conv2D)                (None, 16, 16, 1024) 4718592     max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_14 (BatchNormalization)    (None, 16, 16, 1024) 4096        conv_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 16, 16, 1024) 0           norm_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_15 (Conv2D)                (None, 16, 16, 512)  524288      leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_15 (BatchNormalization)    (None, 16, 16, 512)  2048        conv_15[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 16, 16, 512)  0           norm_15[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_16 (Conv2D)                (None, 16, 16, 1024) 4718592     leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_16 (BatchNormalization)    (None, 16, 16, 1024) 4096        conv_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 16, 16, 1024) 0           norm_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_17 (Conv2D)                (None, 16, 16, 512)  524288      leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_17 (BatchNormalization)    (None, 16, 16, 512)  2048        conv_17[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 16, 16, 512)  0           norm_17[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_18 (Conv2D)                (None, 16, 16, 1024) 4718592     leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_18 (BatchNormalization)    (None, 16, 16, 1024) 4096        conv_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 16, 16, 1024) 0           norm_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_19 (Conv2D)                (None, 16, 16, 1024) 9437184     leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_19 (BatchNormalization)    (None, 16, 16, 1024) 4096        conv_19[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_21 (Conv2D)                (None, 32, 32, 64)   32768       leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 16, 16, 1024) 0           norm_19[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_21 (BatchNormalization)    (None, 32, 32, 64)   256         conv_21[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_20 (Conv2D)                (None, 16, 16, 1024) 9437184     leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 32, 32, 64)   0           norm_21[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_20 (BatchNormalization)    (None, 16, 16, 1024) 4096        conv_20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 16, 16, 256)  0           leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 16, 16, 1024) 0           norm_20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 16, 16, 1280) 0           lambda_1[0][0]                   \n",
      "                                                                 leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_22 (Conv2D)                (None, 16, 16, 1024) 11796480    concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "norm_22 (BatchNormalization)    (None, 16, 16, 1024) 4096        conv_22[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, 16, 16, 1024) 0           norm_22[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 52,972,768\n",
      "Trainable params: 52,952,096\n",
      "Non-trainable params: 20,672\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class  TinyYoloFeature(BaseFeatureExtractor):\n",
    "    \n",
    "    def __init__( self, input_size ):\n",
    "        \n",
    "        input_image  = Input(shape= ( input_size , input_size , 3 ))\n",
    "        \n",
    "        def Conv_Block(inputs , filters , kernel_size = 3 , stride = 1 , padding = 'same' , name = 1, use_bias = False  , use_maxpooling = False):\n",
    "            \n",
    "            x = Conv2D( filters , (kernel_size , kernel_size) , strides=stride , padding = padding , name = 'conv_'+ str(name), use_bias = False )(inputs)\n",
    "            x = BatchNormalization(name = 'nor_' + str(name))(x)\n",
    "            x = LeakyReLU(alpha=0.1)(x)\n",
    "            if use_maxpooling:\n",
    "                x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "            return x\n",
    "        \n",
    "        \n",
    "        x = Conv_Block(input_image , 16 , kernel_size=3 , stride=1 , padding='same', name = 1, use_bias=False , use_maxpooling=True )\n",
    "        \n",
    "        for i in range(0 ,4):\n",
    "            x = Conv_Block(x , 32*(2**i) , kernel_size=3 , stride= 1 , padding='same', name = i+2 , use_bias=False , use_maxpooling=True )\n",
    "            \n",
    "        \n",
    "        x = Conv_Block( x , 512 , kernel_size= 3 , name = 6 ,  use_bias= False , use_maxpooling=True )\n",
    "        \n",
    "        for i  in range(0,2 ):\n",
    "            x = Conv_Block( x , 1024 , kernel_size=3 , name = (i+7) , use_maxpooling=True )\n",
    "        \n",
    "        self.feature_extractor = Model(input_image, x)  \n",
    "        #self.feature_extractor.load_weights(TINY_YOLO_BACKEND_PATH)\n",
    "        \n",
    "    def normalize( self, image ):\n",
    "        return image /255.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TinyYoloFeature(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 512, 512, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv2D)              (None, 512, 512, 16)      432       \n",
      "_________________________________________________________________\n",
      "nor_1 (BatchNormalization)   (None, 512, 512, 16)      64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)   (None, 512, 512, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 256, 256, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 256, 256, 32)      4608      \n",
      "_________________________________________________________________\n",
      "nor_2 (BatchNormalization)   (None, 256, 256, 32)      128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)   (None, 256, 256, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              (None, 128, 128, 64)      18432     \n",
      "_________________________________________________________________\n",
      "nor_3 (BatchNormalization)   (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv2D)              (None, 64, 64, 128)       73728     \n",
      "_________________________________________________________________\n",
      "nor_4 (BatchNormalization)   (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_5 (Conv2D)              (None, 32, 32, 256)       294912    \n",
      "_________________________________________________________________\n",
      "nor_5 (BatchNormalization)   (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_6 (Conv2D)              (None, 16, 16, 512)       1179648   \n",
      "_________________________________________________________________\n",
      "nor_6 (BatchNormalization)   (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_7 (Conv2D)              (None, 8, 8, 1024)        4718592   \n",
      "_________________________________________________________________\n",
      "nor_7 (BatchNormalization)   (None, 8, 8, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)   (None, 8, 8, 1024)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_8 (Conv2D)              (None, 4, 4, 1024)        9437184   \n",
      "_________________________________________________________________\n",
      "nor_8 (BatchNormalization)   (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)   (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 2, 2, 1024)        0         \n",
      "=================================================================\n",
      "Total params: 15,739,760\n",
      "Trainable params: 15,733,648\n",
      "Non-trainable params: 6,112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNetFeature(BaseFeatureExtractor):\n",
    "    \n",
    "    def __init__( self, input_size ):\n",
    "        \n",
    "        input_image  =  Input(shape = (input_size , input_size , 3 ))\n",
    "        mobilenet    =  MobileNet(input_shape = (244 , 244 , 3 ) , include_top = False )\n",
    "        #mobilenet.load_weights(MOBILENET_BACKEND_PATH)\n",
    "        x = mobilenet(input_image)\n",
    "        \n",
    "        self.feature_extractor = Model(input_image, x) \n",
    "        \n",
    "        \n",
    "    \n",
    "    def normalize(self, image):\n",
    "        image = image / 255.\n",
    "        image = image  - 0.5\n",
    "        image = image *2.\n",
    "        return image\n",
    "    \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras_applications\\mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 512, 512, 3)       0         \n",
      "_________________________________________________________________\n",
      "mobilenet_1.00_224 (Model)   multiple                  3228864   \n",
      "=================================================================\n",
      "Total params: 3,228,864\n",
      "Trainable params: 3,206,976\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = MobileNetFeature(512)\n",
    "model.feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqueezeNetFeature(BaseFeatureExtractor):\n",
    "    \"\"\"docstring for ClassName\"\"\"\n",
    "    def __init__(self, input_size):\n",
    "\n",
    "        # define some auxiliary variables and the fire module\n",
    "        sq1x1  = \"squeeze1x1\"\n",
    "        exp1x1 = \"expand1x1\"\n",
    "        exp3x3 = \"expand3x3\"\n",
    "        relu   = \"relu_\"\n",
    "\n",
    "        def fire_module(x, fire_id, squeeze=16, expand=64):\n",
    "            s_id = 'fire' + str(fire_id) + '/'\n",
    "\n",
    "            x     = Conv2D(squeeze, (1, 1), padding='valid', name=s_id + sq1x1)(x)\n",
    "            x     = Activation('relu', name=s_id + relu + sq1x1)(x)\n",
    "\n",
    "            left  = Conv2D(expand,  (1, 1), padding='valid', name=s_id + exp1x1)(x)\n",
    "            left  = Activation('relu', name=s_id + relu + exp1x1)(left)\n",
    "\n",
    "            right = Conv2D(expand,  (3, 3), padding='same',  name=s_id + exp3x3)(x)\n",
    "            right = Activation('relu', name=s_id + relu + exp3x3)(right)\n",
    "\n",
    "            x = concatenate([left, right], axis=3, name=s_id + 'concat')\n",
    "\n",
    "            return x\n",
    "\n",
    "        # define the model of SqueezeNet\n",
    "        input_image = Input(shape=(input_size, input_size, 3))\n",
    "\n",
    "        x = Conv2D(64, (3, 3), strides=(2, 2), padding='valid', name='conv1')(input_image)\n",
    "        x = Activation('relu', name='relu_conv1')(x)\n",
    "        x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "        x = fire_module(x, fire_id=2, squeeze=16, expand=64)\n",
    "        x = fire_module(x, fire_id=3, squeeze=16, expand=64)\n",
    "        x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool3')(x)\n",
    "\n",
    "        x = fire_module(x, fire_id=4, squeeze=32, expand=128)\n",
    "        x = fire_module(x, fire_id=5, squeeze=32, expand=128)\n",
    "        x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool5')(x)\n",
    "\n",
    "        x = fire_module(x, fire_id=6, squeeze=48, expand=192)\n",
    "        x = fire_module(x, fire_id=7, squeeze=48, expand=192)\n",
    "        x = fire_module(x, fire_id=8, squeeze=64, expand=256)\n",
    "        x = fire_module(x, fire_id=9, squeeze=64, expand=256)\n",
    "\n",
    "        self.feature_extractor = Model(input_image, x)  \n",
    "        #self.feature_extractor.load_weights(SQUEEZENET_BACKEND_PATH)\n",
    "\n",
    "    def normalize(self, image):\n",
    "        image = image[..., ::-1]\n",
    "        image = image.astype('float')\n",
    "\n",
    "        image[..., 0] -= 103.939\n",
    "        image[..., 1] -= 116.779\n",
    "        image[..., 2] -= 123.68\n",
    "\n",
    "        return image    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 512, 512, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 255, 255, 64) 1792        input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv1 (Activation)         (None, 255, 255, 64) 0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 127, 127, 64) 0           relu_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fire2/squeeze1x1 (Conv2D)       (None, 127, 127, 16) 1040        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_squeeze1x1 (Activati (None, 127, 127, 16) 0           fire2/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand1x1 (Conv2D)        (None, 127, 127, 64) 1088        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand3x3 (Conv2D)        (None, 127, 127, 64) 9280        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand1x1 (Activatio (None, 127, 127, 64) 0           fire2/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand3x3 (Activatio (None, 127, 127, 64) 0           fire2/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/concat (Concatenate)      (None, 127, 127, 128 0           fire2/relu_expand1x1[0][0]       \n",
      "                                                                 fire2/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire3/squeeze1x1 (Conv2D)       (None, 127, 127, 16) 2064        fire2/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_squeeze1x1 (Activati (None, 127, 127, 16) 0           fire3/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand1x1 (Conv2D)        (None, 127, 127, 64) 1088        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand3x3 (Conv2D)        (None, 127, 127, 64) 9280        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand1x1 (Activatio (None, 127, 127, 64) 0           fire3/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand3x3 (Activatio (None, 127, 127, 64) 0           fire3/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/concat (Concatenate)      (None, 127, 127, 128 0           fire3/relu_expand1x1[0][0]       \n",
      "                                                                 fire3/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 63, 63, 128)  0           fire3/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire4/squeeze1x1 (Conv2D)       (None, 63, 63, 32)   4128        pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_squeeze1x1 (Activati (None, 63, 63, 32)   0           fire4/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand1x1 (Conv2D)        (None, 63, 63, 128)  4224        fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand3x3 (Conv2D)        (None, 63, 63, 128)  36992       fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand1x1 (Activatio (None, 63, 63, 128)  0           fire4/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand3x3 (Activatio (None, 63, 63, 128)  0           fire4/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/concat (Concatenate)      (None, 63, 63, 256)  0           fire4/relu_expand1x1[0][0]       \n",
      "                                                                 fire4/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire5/squeeze1x1 (Conv2D)       (None, 63, 63, 32)   8224        fire4/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_squeeze1x1 (Activati (None, 63, 63, 32)   0           fire5/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand1x1 (Conv2D)        (None, 63, 63, 128)  4224        fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand3x3 (Conv2D)        (None, 63, 63, 128)  36992       fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand1x1 (Activatio (None, 63, 63, 128)  0           fire5/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand3x3 (Activatio (None, 63, 63, 128)  0           fire5/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/concat (Concatenate)      (None, 63, 63, 256)  0           fire5/relu_expand1x1[0][0]       \n",
      "                                                                 fire5/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 31, 31, 256)  0           fire5/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire6/squeeze1x1 (Conv2D)       (None, 31, 31, 48)   12336       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_squeeze1x1 (Activati (None, 31, 31, 48)   0           fire6/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand1x1 (Conv2D)        (None, 31, 31, 192)  9408        fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand3x3 (Conv2D)        (None, 31, 31, 192)  83136       fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand1x1 (Activatio (None, 31, 31, 192)  0           fire6/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand3x3 (Activatio (None, 31, 31, 192)  0           fire6/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/concat (Concatenate)      (None, 31, 31, 384)  0           fire6/relu_expand1x1[0][0]       \n",
      "                                                                 fire6/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire7/squeeze1x1 (Conv2D)       (None, 31, 31, 48)   18480       fire6/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_squeeze1x1 (Activati (None, 31, 31, 48)   0           fire7/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand1x1 (Conv2D)        (None, 31, 31, 192)  9408        fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand3x3 (Conv2D)        (None, 31, 31, 192)  83136       fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand1x1 (Activatio (None, 31, 31, 192)  0           fire7/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand3x3 (Activatio (None, 31, 31, 192)  0           fire7/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/concat (Concatenate)      (None, 31, 31, 384)  0           fire7/relu_expand1x1[0][0]       \n",
      "                                                                 fire7/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire8/squeeze1x1 (Conv2D)       (None, 31, 31, 64)   24640       fire7/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_squeeze1x1 (Activati (None, 31, 31, 64)   0           fire8/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand1x1 (Conv2D)        (None, 31, 31, 256)  16640       fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand3x3 (Conv2D)        (None, 31, 31, 256)  147712      fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand1x1 (Activatio (None, 31, 31, 256)  0           fire8/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand3x3 (Activatio (None, 31, 31, 256)  0           fire8/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/concat (Concatenate)      (None, 31, 31, 512)  0           fire8/relu_expand1x1[0][0]       \n",
      "                                                                 fire8/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire9/squeeze1x1 (Conv2D)       (None, 31, 31, 64)   32832       fire8/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_squeeze1x1 (Activati (None, 31, 31, 64)   0           fire9/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand1x1 (Conv2D)        (None, 31, 31, 256)  16640       fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand3x3 (Conv2D)        (None, 31, 31, 256)  147712      fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand1x1 (Activatio (None, 31, 31, 256)  0           fire9/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand3x3 (Activatio (None, 31, 31, 256)  0           fire9/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/concat (Concatenate)      (None, 31, 31, 512)  0           fire9/relu_expand1x1[0][0]       \n",
      "                                                                 fire9/relu_expand3x3[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 722,496\n",
      "Trainable params: 722,496\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = SqueezeNetFeature(512)\n",
    "model.feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception3Feature(BaseFeatureExtractor):\n",
    "    \"\"\"docstring for ClassName\"\"\"\n",
    "    def __init__(self, input_size):\n",
    "        input_image = Input(shape=(input_size, input_size, 3))\n",
    "\n",
    "        inception = InceptionV3(input_shape=(input_size,input_size,3), include_top=False)\n",
    "        #inception.load_weights(INCEPTION3_BACKEND_PATH)\n",
    "\n",
    "        x = inception(input_image)\n",
    "\n",
    "        self.feature_extractor = Model(input_image, x)  \n",
    "\n",
    "    def normalize(self, image):\n",
    "        image = image / 255.\n",
    "        image = image - 0.5\n",
    "        image = image * 2.\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 16s 0us/step\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 512, 512, 3)       0         \n",
      "_________________________________________________________________\n",
      "inception_v3 (Model)         (None, 14, 14, 2048)      21802784  \n",
      "=================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Inception3Feature(512)\n",
    "model.feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16Feature(BaseFeatureExtractor):\n",
    "    \"\"\"docstring for ClassName\"\"\"\n",
    "    def __init__(self, input_size):\n",
    "        vgg16 = VGG16(input_shape=(input_size, input_size, 3), include_top=False)\n",
    "        #vgg16.load_weights(VGG16_BACKEND_PATH)\n",
    "\n",
    "        self.feature_extractor = vgg16\n",
    "\n",
    "    def normalize(self, image):\n",
    "        image = image[..., ::-1]\n",
    "        image = image.astype('float')\n",
    "\n",
    "        image[..., 0] -= 103.939\n",
    "        image[..., 1] -= 116.779\n",
    "        image[..., 2] -= 123.68\n",
    "\n",
    "        return image \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 13s 0us/step\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 512, 512, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 512, 512, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 512, 512, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 256, 256, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 256, 256, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 256, 256, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 128, 128, 256)     295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 128, 128, 256)     590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 128, 128, 256)     590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 64, 64, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 64, 64, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 64, 64, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = VGG16Feature(512)\n",
    "model.feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50Feature(BaseFeatureExtractor):\n",
    "    \"\"\"docstring for ClassName\"\"\"\n",
    "    def __init__(self, input_size):\n",
    "        resnet50 = ResNet50(input_shape=(input_size, input_size, 3), include_top=False)\n",
    "        resnet50.layers.pop() # remove the average pooling layer\n",
    "        #resnet50.load_weights(RESNET50_BACKEND_PATH)\n",
    "\n",
    "        self.feature_extractor = Model(resnet50.layers[0].input, resnet50.layers[-1].output)\n",
    "\n",
    "    def normalize(self, image):\n",
    "        image = image[..., ::-1]\n",
    "        image = image.astype('float')\n",
    "\n",
    "        image[..., 0] -= 103.939\n",
    "        image[..., 1] -= 116.779\n",
    "        image[..., 2] -= 123.68\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94658560/94653016 [==============================] - 20s 0us/step\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           (None, 512, 512, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 518, 518, 3)  0           input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 256, 256, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 256, 256, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 256, 256, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 258, 258, 64) 0           activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 128, 128, 64) 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 128, 128, 64) 4160        max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 128, 128, 64) 256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 128, 128, 64) 0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 128, 128, 64) 36928       activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 128, 128, 64) 256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 128, 128, 64) 0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 128, 128, 256 16640       activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 128, 128, 256 16640       max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 128, 128, 256 1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 128, 128, 256 1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 128, 128, 256 0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 128, 128, 256 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 128, 128, 64) 16448       activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 128, 128, 64) 256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 128, 128, 64) 0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 128, 128, 64) 36928       activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 128, 128, 64) 256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 128, 128, 64) 0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 128, 128, 256 16640       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 128, 128, 256 1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 128, 128, 256 0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 128, 128, 256 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 128, 128, 64) 16448       activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 128, 128, 64) 256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 128, 128, 64) 0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 128, 128, 64) 36928       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 128, 128, 64) 256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 128, 128, 64) 0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 128, 128, 256 16640       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 128, 128, 256 1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128, 128, 256 0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 128, 128, 256 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 64, 64, 128)  32896       activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 64, 64, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 64, 64, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 64, 64, 128)  147584      activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 64, 64, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 64, 64, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 64, 64, 512)  66048       activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 64, 64, 512)  131584      activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 64, 64, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 64, 64, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 64, 64, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 64, 64, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 64, 64, 128)  65664       activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 64, 64, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 64, 64, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 64, 64, 128)  147584      activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 64, 64, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 64, 64, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 64, 64, 512)  66048       activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 64, 64, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 64, 64, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 64, 64, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 64, 64, 128)  65664       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 64, 64, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 64, 64, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 64, 64, 128)  147584      activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 64, 64, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 64, 64, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 64, 64, 512)  66048       activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 64, 64, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 64, 64, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 64, 64, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 64, 64, 128)  65664       activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 64, 64, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 64, 64, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 64, 64, 128)  147584      activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 64, 64, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 64, 64, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 64, 64, 512)  66048       activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 64, 64, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 64, 64, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 64, 64, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 32, 32, 256)  131328      activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 32, 32, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 32, 32, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 32, 32, 256)  590080      activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 32, 32, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 32, 32, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 32, 32, 1024) 263168      activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 32, 32, 1024) 525312      activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 32, 32, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 32, 32, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 32, 32, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 32, 32, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 32, 32, 256)  262400      activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 32, 32, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 32, 32, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 32, 32, 256)  590080      activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 32, 32, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 32, 32, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 32, 32, 1024) 263168      activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 32, 32, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 32, 32, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 32, 32, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 32, 32, 256)  262400      activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 32, 32, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 32, 32, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 32, 32, 256)  590080      activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 32, 32, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 32, 32, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 32, 32, 1024) 263168      activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 32, 32, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 32, 32, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 32, 32, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 32, 32, 256)  262400      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 32, 32, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 32, 32, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 32, 32, 256)  590080      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 32, 32, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 32, 32, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 32, 32, 1024) 263168      activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 32, 32, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 32, 32, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 32, 32, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 32, 32, 256)  262400      activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 32, 32, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 32, 32, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 32, 32, 256)  590080      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 32, 32, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 32, 32, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 32, 32, 1024) 263168      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 32, 32, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 32, 32, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 32, 32, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 32, 32, 256)  262400      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 32, 32, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 32, 32, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 32, 32, 256)  590080      activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 32, 32, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 32, 32, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 32, 32, 1024) 263168      activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 32, 32, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 32, 32, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 32, 32, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 16, 16, 512)  524800      activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 16, 16, 512)  2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 16, 16, 512)  0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 16, 16, 512)  2359808     activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 16, 16, 512)  2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 16, 16, 512)  0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 16, 16, 2048) 1050624     activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 16, 16, 2048) 2099200     activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 16, 16, 2048) 8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 16, 16, 2048) 8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 16, 16, 2048) 0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 16, 16, 2048) 0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 16, 16, 512)  1049088     activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 16, 16, 512)  2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 16, 16, 512)  0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 16, 16, 512)  2359808     activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 16, 16, 512)  2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 16, 16, 512)  0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 16, 16, 2048) 1050624     activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 16, 16, 2048) 8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 16, 16, 2048) 0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 16, 16, 2048) 0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 16, 16, 512)  1049088     activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 16, 16, 512)  2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 16, 16, 512)  0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 16, 16, 512)  2359808     activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 16, 16, 512)  2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 16, 16, 512)  0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 16, 16, 2048) 1050624     activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 16, 16, 2048) 8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 16, 16, 2048) 0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_140[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50Feature(512)\n",
    "model.feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
